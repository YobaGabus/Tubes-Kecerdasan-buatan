{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNAt8T0giN8Wa4OB6dmhxmK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YobaGabus/Tubes-Kecerdasan-buatan/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "-7xMtaap4Ukl",
        "outputId": "84056fdd-b23e-4a4a-a761-445f79a733a1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-97368fdc20e9>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    from keras.layers.convolutional import MaxPooling2D from keras.layers.core import Activation\u001b[0m\n\u001b[0m                                                           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten from keras.layers.core import Dense from keras.layers.core import Dropout from\n",
        "keras.models import Sequential from keras import callbacks\n",
        "\n",
        "DEV = False argvs = sys.argv\n",
        "argc = len(argvs)\n",
        "if argc > 1 and (argvs[1] == \"--development\" or argvs[1]\n",
        "== \"-d\"):\n",
        "DEV = True if DEV:\n",
        "epochs = 2 else:\n",
        "epochs = 500 ##100\n",
        "\n",
        "train_data_path = 'D:/mushrooms-classification-common- genuss-images/Mushrooms/data/train' validation_data_path =\n",
        "'D:/mushrooms-classification- common-genuss-images/Mushrooms/data/validation'\n",
        "\n",
        "\"\"\"\n",
        "Parameters \"\"\"\n",
        "\n",
        "img_width, img_height = 64,64 batch_size = 30\n",
        "samples_per_epoch = 416\n",
        "validation_steps = 104\n",
        "nb_filters1 = 32\n",
        "nb_filters2 = 64\n",
        "conv1_size = 3\n",
        "conv2_size = 3\n",
        "pool_size = 2\n",
        "classes_num = 2\n",
        "lr = 0.001\n",
        "\n",
        "\n",
        "\n",
        "model = Sequential() model.add(Conv2D(nb_filters1,(conv1_size, conv1_size), padding =\"same\",\n",
        "input_shape=(img_width, img_height, 3))) model.add(Activation(\"relu\")) model.add(MaxPooling2D(pool_size=(pool_size,\n",
        "pool_size)))\n",
        "model.add(Conv2D(nb_filters2, (conv2_size, conv2_size), padding =\"same\"))\n",
        "model.add(Activation(\"relu\")) model.add(MaxPooling2D(pool_size=(pool_size, pool_size),\n",
        "dim_ordering='th'))\n",
        "model.add(Flatten()) model.add(Dense(256))\n",
        "model.add(Activation(\"relu\")) model.add(Dropout(0.5)) model.add(Dense(classes_num, activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "optimizer=optimizers.RMSprop(rho=0.9), metrics=['accuracy'])\n",
        "\n",
        "train_datagen = ImageDataGenerator( rescale=1./255,\n",
        "shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255) train_generator = train_datagen.flow_from_directory(\n",
        "train_data_path, target_size=(img_height, img_width), batch_size=batch_size, class_mode='categorical')\n",
        "validation_generator =\n",
        "test_datagen.flow_from_directory( validation_data_path, target_size=(img_height, img_width), batch_size=batch_size,\n",
        "class_mode='categorical')\n",
        "\n",
        "\"\"\"\n",
        "Tensorboard log \"\"\"\n",
        "log_dir = './tf-log/tf- log(epoch=100,lr=0.001,Op=adam)/'\n",
        "tb_cb = callbacks.TensorBoard(log_dir=log_dir, histogram_freq=0)\n",
        "\n",
        "\n",
        "\n",
        "cbks = [tb_cb]\n",
        "\n",
        "from time import time import time\n",
        "from tensorflow.python.keras.callbacks import TensorBoard\n",
        "name = \"jamur {}\".format(int(time.time()))\n",
        "tensorboard =\n",
        "TensorBoard(log_dir='logs/{}'.format(name)) tensorboard\n",
        "\n",
        "model.fit_generator( train_generator,\n",
        "samples_per_epoch=samples_per_epoch, epochs=epochs, validation_data=validation_generator,\n",
        "validation_steps=validation_steps, callbacks=[tensorboard])\n",
        "\n",
        "target_dir = 'D:/mushrooms-classification-common- genuss- images/Mushrooms/data/models/model(epoch=100,lr=0.001,O\n",
        "p=adam)/'\n",
        "if not os.path.exists(target_dir): os.mkdir(target_dir)\n",
        "model.save('D:/mushrooms-classification-common-genuss- images/Mushrooms/data/models/model(epoch=100,lr=0.001,O\n",
        "p=adam)/model.h5')\n",
        "model.save_weights('D:/mushrooms-classification-common- genuss- images/Mushrooms/data/models/model(epoch=100,lr=0.001,O\n",
        "p=adam)/weights.h5')\n",
        "\n",
        "import numpy\n",
        "test_steps_per_epoch =\n",
        "numpy.math.ceil(validation_generator.samples / validation_generator.batch_size)\n",
        "\n",
        "predictions =\n",
        "model.predict_generator(validation_generator, steps=test_steps_per_epoch)\n",
        "# Get most likely class\n",
        "predicted_classes = numpy.argmax(predictions, axis=1) predicted_classes\n",
        "\n",
        "true_classes = validation_generator.classes\n",
        "\n",
        "\n",
        "\n",
        "class_labels =\n",
        "list(validation_generator.class_indices.keys())\n",
        "\n",
        "import sklearn.metrics as metrics\n",
        "report = metrics.classification_report(true_classes, predicted_classes, target_names=class_labels) print(report)"
      ]
    }
  ]
}